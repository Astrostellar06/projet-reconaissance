{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport de projet de détection et de reconnaissance faciale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection de visage - Cascade de Haar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Détection à partir d'une image ou d'un flux vidéo\n",
    "\n",
    "Le code suivant permet de détecter un visage en prenant comme entrée la webcam de l'ordinateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")  # On charge le classifieur de visage\n",
    "\n",
    "video_capture = cv2.VideoCapture(0) # On ouvre la webcam\n",
    "while True:\n",
    "    ret, frame = video_capture.read()   # On récupère une image de la webcam\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    # On la convertit en niveaux de gris\n",
    "    face = face_classifier.detectMultiScale(frame_gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))  # On détecte les visages\n",
    "    if len(face) != 0:  # Si on a détecté des visages\n",
    "        for (x, y, w, h) in face:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)    # On dessine un rectangle autour de chaque visage\n",
    "    cv2.imshow('Video', frame)  # On affiche l'image\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Evaluation des performances\n",
    "\n",
    "On reprend le code pour détecter des visages dans une image, et on évalue ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At image 0 , we have:\n",
      "Average IoU (including false positive and undetected faces): 0.5349095799362508\n",
      "Average IoU not null (only sucessfuly detected faces): 0.5349095799362508\n",
      "Precision (Ratio between successful detection and total detections): 1.0\n",
      "Recall (Ratio between successful detection and total faces): 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (\u001b[38;5;28mint\u001b[39m(x), \u001b[38;5;28mint\u001b[39m(y)), (\u001b[38;5;28mint\u001b[39m(w), \u001b[38;5;28mint\u001b[39m(h)), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)    \u001b[38;5;66;03m# On dessine un rectangle bleu autour des visages prédits\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m average_IoU \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(IoUresults)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage IoU:\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_IoU)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "image_dir = 'images/train'\n",
    "result_dir = 'labels2'\n",
    "result_files = os.listdir(result_dir)\n",
    "IoUresults = []\n",
    "avgIoU = []\n",
    "avgIoUNotNull = []\n",
    "avgPrecision = []\n",
    "avgRecall = []\n",
    "totalIoU = 0\n",
    "IoUNotNull = 0\n",
    "totalCount = 0\n",
    "NotNullCount = 0\n",
    "CountNotDetected = 0\n",
    "# Pour chaque image\n",
    "for i in range(0, len(os.listdir(image_dir))):\n",
    "    filename = os.listdir(image_dir)[i]\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    image = cv2.imread(image_path) # On charge l'image\n",
    "\n",
    "    frame_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # On la convertit en niveaux de gris\n",
    "    face = face_classifier.detectMultiScale(frame_gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40)) # On détecte les visages\n",
    "\n",
    "    result_path = os.path.join(result_dir, filename.replace('.jpg', '.txt').replace('.png', '.txt')) # On récupère le fichier de résultat\n",
    "    result = open(result_path, \"r\").read().splitlines()\n",
    "    result = [list(map(str, x.split())) for x in result]\n",
    "\n",
    "    # Pour chaque visage détecté\n",
    "    IoU = []\n",
    "    for (x, y, w, h) in face:\n",
    "        x1, y1, x2, y2 = x, y, x+w, y+h # On récupère les coordonnées du visage\n",
    "        currentIoU = 0\n",
    "        for rect in result:\n",
    "            _, _, x1_val, y1_val, x2_val, y2_val = rect # On récupère les coordonnées indiquées dans le fichier de résultat\n",
    "            x1_val, y1_val, x2_val, y2_val = float(x1_val), float(y1_val), float(x2_val), float(y2_val)\n",
    "            # On cherche les coordonnées du coin supérieur gauche et inférieur droit du rectangle d'intersection\n",
    "            x1_i = max(x1, x1_val)\n",
    "            y1_i = max(y1, y1_val)\n",
    "            x2_i = min(x2, x2_val)\n",
    "            y2_i = min(y2, y2_val)\n",
    "            # On vérifie que le rectangle d'intersection est valide\n",
    "            if x1_i < x2_i and y1_i < y2_i:\n",
    "                # On calcule la surface du rectangle d'intersection\n",
    "                surface = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "                # On calcule la surface de l'union du rectangle prédit et du rectangle détecté\n",
    "                union = (x2 - x1) * (y2 - y1) + (x2_val - x1_val) * (y2_val - y1_val) - surface\n",
    "                newIoU = surface / union # On calcule l'IoU\n",
    "                # Si l'IoU est supérieur à l'IoU actuel, on le met à jour (on cherche le meilleur match entre les visages détectés et les visages prédits)\n",
    "                if newIoU > currentIoU:\n",
    "                    currentIoU = newIoU\n",
    "        IoU.append(currentIoU)\n",
    "        totalIoU += currentIoU\n",
    "        totalCount += 1\n",
    "        if currentIoU > 0: # Si l'IoU est non nul, on a détecté un visage avec succès\n",
    "            IoUNotNull += currentIoU\n",
    "            NotNullCount += 1\n",
    "    if len(IoU) < len(result):\n",
    "        for j in range(len(IoU), len(result)): # Si on n'a pas détecté tous les visages, on ajoute des 0 à l'IoU\n",
    "            IoU.append(0)\n",
    "            CountNotDetected += 1\n",
    "    IoUresults.append(IoU)\n",
    "\n",
    "    avgIoU.append(totalIoU/(totalCount+CountNotDetected))\n",
    "    avgIoUNotNull.append(IoUNotNull/NotNullCount)\n",
    "    avgPrecision.append(NotNullCount/totalCount)\n",
    "    avgRecall.append(NotNullCount/(NotNullCount+CountNotDetected))\n",
    "    if i%100 == 0:\n",
    "        print(\"At image\", i, \", we have:\")\n",
    "        print(\"Average IoU (including false positive and undetected faces):\", totalIoU/(totalCount+CountNotDetected))\n",
    "        print(\"Average IoU not null (only sucessfuly detected faces):\", IoUNotNull/NotNullCount)\n",
    "        print(\"Precision (Ratio between successful detection and total detections):\", NotNullCount/totalCount)\n",
    "        print(\"Recall (Ratio between successful detection and total faces):\", NotNullCount/(NotNullCount+CountNotDetected))\n",
    "\n",
    "    if i%1000 == 0:\n",
    "        plt.plot(avgIoU)\n",
    "        plt.plot(avgIoUNotNull)\n",
    "        plt.plot(avgPrecision)\n",
    "        plt.plot(avgRecall)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    if len(face) != 0:\n",
    "        for i in range (0, len(face)):\n",
    "            (x, y, w, h) = face[i]\n",
    "            if IoU[i] > 0.5:\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)    # On dessine un rectangle vert autour des visages bien détectés (IoU > 0.5)\n",
    "            else:\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)    # On dessine un rectangle rouge autour des visages mal détectés (IoU <= 0.5)\n",
    "    if len(result) != 0:\n",
    "        for (_, _, x, y, w, h) in result:\n",
    "            x, y, w, h = float(x), float(y), float(w), float(h)\n",
    "            cv2.rectangle(image, (int(x), int(y)), (int(w), int(h)), (255, 0, 0), 2)    # On dessine un rectangle bleu autour des visages prédits\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "average_IoU = np.mean(IoUresults)\n",
    "print(\"Average IoU:\", average_IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir laissé tourner cet algorithme pour 2000 images, nous obtenons les résultats suivants :\n",
    "\n",
    "![Resultats IoU](resultIoU3.png)\n",
    "\n",
    "![Resultats IoU graphe](resultIoU2.png)\n",
    "\n",
    "Avec en vert la précision, en orange l'IoU sans prendre en compte les non-détections, en rouge le rappel, et en bleu l'IoU prenant en compte les faux positifs et les non-détections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Interprétation\n",
    "\n",
    "Nous voyons que dans 75% des cas où le modèle nous indique qu'il y a un visage, la prédiction se révèle juste (précision du modèle). Cela est un résultat prometteur, mais qui n'est pas complètement satisfaisant, avec un taux de 25% de faux-positifs.\n",
    "\n",
    "Une autre statistique intéressante est le taux de rappel. Le modèle ne détecte que 45% des visages présents dans les photos. Ce résultat reste assez bas, et pourrait être grandement amélioré.\n",
    "\n",
    "Enfin, l'IoU, qui est le rapport de surface entre les visages détectés et les visages prédits, a une valeur de 0.6 quand les visages sont détectés avec succès, ce qui signifie que le modèle parvient à déceler le visage de manière correcte. Encore une fois, c'est un score qui pourrait être largement amélioré.\n",
    "\n",
    "Nous avons également calculé l'IoU de manière plus globale, en prenant en compte les faux positifs et les non-détections de visage. Cela fait naturellement descendre fortement l'IoU, avec un IoU à environ 0.25. Cela traduit un manque de finesse dans la détection des visages par le modèle.\n",
    "\n",
    "Finalement, ces statistiques nous indiquent que le modèle est fonctionnel et parvient à détecter avec succès des visages dans des images, mais il n'est pas assez performant, et a un taux d'erreur encore très important. Cependant, il est intéressant de noter que l'un des avntages de ce modèle est sa rapidité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconnaissance de visages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Méthode de l'ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code que nous avons utiliser pour implémenter la méthode de l'ACP pour la reconnsaissance de visages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)  # On charge le dataset LFW avec un minimum de 70 images par personne et une taille de 0.4\n",
    "\n",
    "# On en extrait les caractéristiques et les labels\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "print(\"Total dataset size: %d\" % X.shape[0])\n",
    "\n",
    "# Diviser les données en un ensemble d'entraînement et un ensemble de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
    "\n",
    "# Appliquer l'ACP pour réduire la dimensionnalité\n",
    "n_components = 100  # Nombre de composantes principales (hyperparamètre à optimiser)\n",
    "print(\"Number of components: \", n_components)\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)    # Appliquer la transformation aux données d'entraînement\n",
    "X_test_pca = pca.transform(X_test)\n",
    "eigenfaces = pca.components_.reshape((n_components, lfw_people.images.shape[1], lfw_people.images.shape[2]))    # Récupérer les eigenfaces\n",
    "clf = SVC(kernel='rbf', class_weight='balanced')\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca) # On prédit les noms des personnes sur l'ensemble de test\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))     # Afficher les résultats de classification\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):   # Fonction pour afficher les images\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):     # Fonction pour afficher le nom prédit et le nom réel\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    if pred_name == true_name:\n",
    "        return \"Predicted: \" + pred_name + \"\\nReality: \" + true_name + \"\\nCorrect\"\n",
    "    else:\n",
    "        return \"Predicted: \" + pred_name + \"\\nReality: \" + true_name + \"\\nIncorrect\"\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, lfw_people.images.shape[1], lfw_people.images.shape[2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir testé plusieurs valeurs pour le nombre de composantes principales (25, 50, 100, 150, 200, 300), nous sommes arrivés à la conclusion que 100 semblait être l'hyperparamètre le plus adapté à notre situation.  \n",
    "Cela permet en effet d'optimiser au mieux la valeur du F1-score (89%), qui est calculé comme étant `2 / (1/precision + 1/recall)`, et permettant d'avoir une métrique reliant la précision au taux de rappel. Plus le F1-score est élevé, plus le modèle est efficace (1.0 étant la valeur maximale théorique).  \n",
    "Une valeur plus faible résulterait en un modèle moins entraîné, donc moins bon. Une valeur plus haute nuirait au modèle en l'hyperspécialisant.\n",
    "\n",
    "Voici les résultats obtenus avec un tel hyperparamètre :\n",
    "\n",
    "![resultat ACP](resultACP.png)\n",
    "\n",
    "Nous voyons que le modèle a de bons résultats, avec une précision et un taux de rappel autour de 90%. Cela montre l'efficacité du modèle pour reconnaître des visages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
